{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from collections import namedtuple\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. Download data\n",
    "#   1.1 Movies\n",
    "#   1.2 Stars\n",
    "#   1.3 Producers\n",
    "\n",
    "# https://triplydb.com/Triply/linkedmdb/insights/classFrequency?graph=https%3A%2F%2Ftriplydb.com%2FTriply%2Flinkedmdb%2Fgraphs%2Fdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data\n",
    "\n",
    "##### **recommender.py** to extract the movies and serialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies_from_files(folder_path='./movies_data'):\n",
    "    all_movies = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pkl'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                movies = pickle.load(f)\n",
    "                all_movies.extend(movies)\n",
    "\n",
    "    return all_movies\n",
    "\n",
    "def extract_objects(movies:list[str]) -> dict:\n",
    "    \n",
    "    objects = {\n",
    "        \"actors\": set(),\n",
    "        \"directors\": set(),\n",
    "        \"genres\": set(),\n",
    "        \"subjects\": set()\n",
    "    }\n",
    "    \n",
    "    for movie in movies:\n",
    "        \n",
    "        if len(movie.actors) > 0:\n",
    "            for actor in movie.actors.split(\",\"):\n",
    "                objects[\"actors\"].add(actor)\n",
    "                \n",
    "        if len(movie.directors) > 0:\n",
    "            for director in movie.directors.split(\",\"):\n",
    "                objects[\"directors\"].add(director)\n",
    "                \n",
    "        if len(movie.subjects) > 0:\n",
    "            for subject in movie.subjects.split(\",\"):\n",
    "                objects[\"subjects\"].add(subject)\n",
    "                \n",
    "        if len(movie.genres) > 0:\n",
    "            for genre in movie.genres.split(\",\"):\n",
    "                objects[\"genres\"].add(genre)            \n",
    "    \n",
    "    return objects\n",
    "\n",
    "\n",
    "def get_year(movie):\n",
    "    match = re.search(r\"\\d{4}\", movie)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the namedtuples\n",
    "Movie = namedtuple(\"Movie\", \"film_id title release_date genres subjects runtime actors sequel_id prequel_id directors\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movies = load_movies_from_files()\n",
    "\n",
    "release_dates = [movie.release_date for movie in movies if movie.release_date != 0]\n",
    "\n",
    "other_objects = extract_objects(movies)\n",
    "\n",
    "actors = list(other_objects[\"actors\"])\n",
    "directors = list(other_objects[\"directors\"])\n",
    "genres = list(other_objects[\"genres\"])\n",
    "subjects = list(other_objects[\"subjects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = len(movies), len(subjects), len(actors), len(directors), len(genres)\n",
    "column_names = [\"Movies\", \"Subjects\", \"Actors\", \"Directors\", \"Genres\"]\n",
    "widths = [max(len(str(d)), len(column_name)) + 2 for d, column_name in zip(data, column_names)]\n",
    "\n",
    "for column_name, width in zip(column_names, widths):\n",
    "    print(column_name.center(width), end=\"\")\n",
    "print()\n",
    "\n",
    "# Print data\n",
    "for d, width in zip(data, widths):\n",
    "    print(str(d).center(width), end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_helper_nodes(G, nodes:list[str], node_type:str):\n",
    "    for node in nodes:\n",
    "        G.add_node(node, type=node_type, label=node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all unique attributes into nodes from KG.\n",
    "# Idea: Relate movies by their matching unique attributes (that are now nodes), and can be traversed over them as a bridge between the movies.\n",
    "\n",
    "# Note: Graphen werden aus ID gebildet, und es werden keine weiteren Infos in betracht gezogen. Daher UNIQUE ID f√ºr jeden Node.\n",
    "\n",
    "G = nx.Graph() # LIEBER BI-DIRECTIONAL\n",
    "\n",
    "helper_nodes = zip([actors, directors, genres, subjects], [\"actor\", \"director\", \"genre\", \"subject\"])\n",
    "for category, node_type in helper_nodes:\n",
    "    print(category, node_type)\n",
    "    create_helper_nodes(G, category, node_type=node_type)\n",
    "\n",
    "# runtime \n",
    "G.add_node(\"runtime_short\", type=\"runtime\", label=\"short runtime\")\n",
    "G.add_node(\"runtime_long\", type=\"runtime\", label=\"long runtime\")\n",
    "\n",
    "for movie in movies:\n",
    "    # Create a movie node\n",
    "    G.add_node(movie.film_id, type='movie', label=movie.title)\n",
    "    \n",
    "    # Splitting and adding genre nodes\n",
    "    if movie.genres:\n",
    "        for genre in movie.genres.split(\",\"):\n",
    "            G.add_edge(movie.film_id, genre, relationship='HAS_GENRE')\n",
    "\n",
    "    # Splitting and adding subject nodes\n",
    "    if movie.subjects:\n",
    "        for subject in movie.subjects.split(\",\"):\n",
    "            G.add_edge(movie.film_id, subject, relationship='HAS_SUBJECT')\n",
    "\n",
    "    # Splitting and adding actor nodes\n",
    "    if movie.actors:\n",
    "        for actor in movie.actors.split(\",\"):\n",
    "            G.add_edge(movie.film_id, actor, relationship='HAS_ACTOR')\n",
    "\n",
    "    # Splitting and adding director nodes\n",
    "    if movie.directors:\n",
    "        for director in movie.directors.split(\",\"):\n",
    "            G.add_edge(movie.film_id, director, relationship='HAS_DIRECTOR')\n",
    "            \n",
    "    # \"predicate\" nodes     \n",
    "    # if movie.release_dates != 0 and movie.release_dates < :\n",
    "    #     G.add_edge(movie.film_id, movie.release_date, relationship='RELEASED_IN')\n",
    "        \n",
    "    if movie.sequel_id != \"\":\n",
    "        G.add_edge(movie.film_id, movie.sequel_id, relationship='SEQUEL')\n",
    "\n",
    "    if movie.prequel_id != \"\":\n",
    "        G.add_edge(movie.film_id, movie.prequel_id, relationship='PREQUEL')\n",
    "\n",
    "    if movie.runtime != 0:\n",
    "        # we are only interested in short and very long movies\n",
    "        runtime = int(float(movie.runtime))\n",
    "        if runtime < 50:\n",
    "            G.add_edge(movie.film_id, \"runtime_short\", relationship='RUNTIME')\n",
    "        elif runtime > 170:\n",
    "            G.add_edge(movie.film_id, \"runtime_long\", relationship='RUNTIME')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('graph.pkl', 'wb') as f:\n",
    "    pickle.dump(G, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make space\n",
    "del movies\n",
    "del actors\n",
    "del release_dates\n",
    "del directors\n",
    "del subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = len(G.nodes()), len(G.edges())\n",
    "column_names = [\"# Nodes\", \"# Edges\"]\n",
    "widths = [max(len(str(d)), len(column_name)) + 2 for d, column_name in zip(data, column_names)]\n",
    "\n",
    "for column_name, width in zip(column_names, widths):\n",
    "    print(column_name.center(width), end=\"\")\n",
    "print()\n",
    "\n",
    "# Print data\n",
    "for d, width in zip(data, widths):\n",
    "    print(str(d).center(width), end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the previous graph G\n",
    "# pos = nx.spring_layout(G)  # Positioning of nodes\n",
    "# plt.figure(figsize=(12, 12))  # Set figure size\n",
    "\n",
    "# # Draw nodes based on their type for differentiated visualization\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[node for node, attr in G.nodes(data=True) if attr['type'] == 'movie'], node_color='blue', node_size=500, label='Movies')\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[node for node, attr in G.nodes(data=True) if attr['type'] == 'genre'], node_color='red', node_size=300, label='Genres')\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[node for node, attr in G.nodes(data=True) if attr['type'] == 'actor'], node_color='yellow', node_size=300, label='Actors')\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[node for node, attr in G.nodes(data=True) if attr['type'] == 'director'], node_color='green', node_size=300, label='Directors')\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[node for node, attr in G.nodes(data=True) if attr['type'] == 'subject'], node_color='purple', node_size=300, label='Subjects')\n",
    "\n",
    "# # Draw edges\n",
    "# nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "# # Draw labels\n",
    "# labels = {node: attr['label'] for node, attr in G.nodes(data=True)}\n",
    "# nx.draw_networkx_labels(G, pos, labels=labels, font_size=10)\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend()\n",
    "\n",
    "# plt.title(\"Movie Graph\")\n",
    "# plt.axis('off')  # Hide axis\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 64\n",
    "walk_length = 20\n",
    "num_walks = 10\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=40, num_walks=200, workers=4, temp_folder=\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del G\n",
    "del category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store file\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('./node2vec.pkl.gz', 'wb') as file:\n",
    "    pickle.dump(node2vec, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings for later use\n",
    "model.save(\"./embeddings.model\")\n",
    "model = Word2Vec.load(\"embeddings.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector for a specific node\n",
    "\n",
    "vector = model.wv['65517']\n",
    "\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# tokens = []\n",
    "\n",
    "# labels = model.wv.index_to_key  \n",
    "# tokens = [model.wv[word] for word in labels]\n",
    "\n",
    "# # Reduce dimensionality with t-SNE\n",
    "# tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23, verbose=1)\n",
    "# new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for value in new_values:\n",
    "#     x.append(value[0])\n",
    "#     y.append(value[1])\n",
    "\n",
    "# node_types = [G.nodes[node]['type'] for node in labels]\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# for i in range(len(x)):\n",
    "#     plt.scatter(x[i], y[i])\n",
    "#     plt.annotate(node_types[i], xy=(x[i], y[i]), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def get_nearest_neighbors(node, model, G, k=10):\n",
    "    target_embedding = model.wv[node]\n",
    "    \n",
    "    similarities = {}\n",
    "    for other_node in model.wv.index_to_key:\n",
    "        if other_node == node or G.nodes[other_node]['type'] != 'movie':  # Skip the given node itself and non-movie nodes\n",
    "            continue\n",
    "        other_embedding = model.wv[other_node]\n",
    "        similarities[other_node] = cosine_similarity(target_embedding, other_embedding)\n",
    "    \n",
    "    sorted_nodes = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    nearest_neighbors = [node[0] for node in sorted_nodes[:k]]\n",
    "    \n",
    "    return nearest_neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_node = \"65517\"\n",
    "neighbors = get_nearest_neighbors(target_node, model, G, k=5)\n",
    "print(neighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
